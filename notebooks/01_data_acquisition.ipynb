{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "623359e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 RAW_DIR: C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\raw\n",
      "📁 CLEAN_DIR: C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\cleaned\n",
      "\n",
      "🔍 Searching in: C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\raw\\laps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing laps: 100%|██████████| 605/605 [00:00<00:00, 844.99it/s]\n",
      "Processing laps: 100%|██████████| 605/605 [00:00<00:00, 844.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\cleaned\\laps.csv\n",
      "\n",
      "🔍 Searching in: C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\raw\\position\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing position: 100%|██████████| 607/607 [00:00<00:00, 1194.87it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\cleaned\\position.csv\n",
      "\n",
      "🔍 Searching in: C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\raw\\stints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing stints: 100%|██████████| 605/605 [00:00<00:00, 1004.44it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\cleaned\\stints.csv\n",
      "\n",
      "🔍 Searching in: C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\raw\\car_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing car_data: 100%|██████████| 116/116 [00:01<00:00, 60.56it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\cleaned\\car_data.csv\n",
      "\n",
      "🔍 Searching in: C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\raw\\race_control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing race_control: 100%|██████████| 115/115 [00:00<00:00, 937.70it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\cleaned\\race_control.csv\n",
      "\n",
      "🔍 Searching in: C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\raw\\weather\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing weather: 100%|██████████| 123/123 [00:00<00:00, 983.93it/s]\n",
      "Processing weather: 100%|██████████| 123/123 [00:00<00:00, 983.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to C:\\Users\\John\\Documents\\Capstone Projects\\Python Capstones\\F1_Analysis\\data\\cleaned\\weather.csv\n"
     ]
    }
   ],
   "source": [
    "# ── 1. Imports ─────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# ── 2. Set Dynamic Project Paths ───────────────────────────\n",
    "# This sets the root folder to the parent of the notebook directory (F1_Analysis)\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "CLEAN_DIR = PROJECT_ROOT / \"data\" / \"cleaned\"\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"📁 RAW_DIR:\", RAW_DIR)\n",
    "print(\"📁 CLEAN_DIR:\", CLEAN_DIR)\n",
    "\n",
    "# ── 3. Combine CSVs Function ───────────────────────────────\n",
    "def combine_csvs(input_folder: Path, output_file: Path, variable: str, has_driver: bool = True):\n",
    "    all_frames = []\n",
    "    pattern_driver = re.compile(rf\"{variable}_(\\d+)_driver(\\d+)\\.csv\", re.IGNORECASE)\n",
    "    pattern_weather = re.compile(rf\"{variable}_(\\d+)\\.csv\", re.IGNORECASE)\n",
    "\n",
    "    print(f\"\\n🔍 Searching in: {input_folder.resolve()}\")\n",
    "    for file in tqdm(sorted(input_folder.rglob(\"*.csv\")), desc=f\"Processing {variable}\"):\n",
    "        fname = file.name\n",
    "\n",
    "        # Match filenames\n",
    "        if has_driver:\n",
    "            match = pattern_driver.match(fname)\n",
    "            if not match:\n",
    "                print(f\"⚠️ Skipping unmatched file: {fname}\")\n",
    "                continue\n",
    "            session_key, driver_number = match.groups()\n",
    "        else:\n",
    "            match = pattern_weather.match(fname)\n",
    "            if not match:\n",
    "                print(f\"⚠️ Skipping unmatched file: {fname}\")\n",
    "                continue\n",
    "            session_key = match.group(1)\n",
    "            driver_number = None\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            df[\"session_key\"] = session_key\n",
    "            if has_driver:\n",
    "                df[\"driver_number\"] = driver_number\n",
    "            all_frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to read {fname}: {e}\")\n",
    "\n",
    "    if all_frames:\n",
    "        combined_df = pd.concat(all_frames, ignore_index=True)\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        print(f\"✅ Saved to {output_file}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No valid files found for {variable}\")\n",
    "\n",
    "# ── 4. Process All Variables ───────────────────────────────\n",
    "variables_all = [\"laps\", \"position\", \"stints\"]\n",
    "verstappen_var = \"car_data\"\n",
    "weather_var = \"weather\"\n",
    "race_control_var = \"race_control\"\n",
    "\n",
    "# Process driver-specific variables\n",
    "for var in variables_all:\n",
    "    combine_csvs(RAW_DIR / var, CLEAN_DIR / f\"{var}.csv\", variable=var)\n",
    "\n",
    "# Verstappen-only\n",
    "combine_csvs(RAW_DIR / verstappen_var, CLEAN_DIR / f\"{verstappen_var}.csv\", variable=verstappen_var)\n",
    "\n",
    "# Weather (no driver)\n",
    "combine_csvs(RAW_DIR / race_control_var, CLEAN_DIR / f\"{race_control_var}.csv\", variable=race_control_var, has_driver=False)\n",
    "\n",
    "# Weather (no driver)\n",
    "combine_csvs(RAW_DIR / weather_var, CLEAN_DIR / f\"{weather_var}.csv\", variable=weather_var, has_driver=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
